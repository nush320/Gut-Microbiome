---
title: "Study 3 - Saffouri DADA Jan 31 2025"
output: html_document
date: "2025-01-31"
---
```{r}
library(dada2)
packageVersion("dada2")
library(ShortRead)
packageVersion("ShortRead")
library(Biostrings)
packageVersion("Biostrings")
```

```{r}
path <- "3-fastq"
list.files(path)
```

```{r}
fnFs <- sort(list.files(path, pattern = "_1.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern = "_2.fastq", full.names = TRUE))
```

# Identify Primers
```{r}
FWD <- "GTGCCAGCMGCCGCGGTAA"  # 515F
REV <- "GGACTACHVGGGTWTCTAAT"  # 806R
```

```{r}
allOrients <- function(primer) {
    # Create all orientations of the input sequence
    require(Biostrings)
    dna <- DNAString(primer)  # The Biostrings works w/ DNAString objects rather than character vectors
    orients <- c(Forward = dna, Complement = Biostrings::complement(dna), Reverse = Biostrings::reverse(dna),
        RevComp = Biostrings::reverseComplement(dna))
    return(sapply(orients, toString))  # Convert back to character vector
}
FWD.orients <- allOrients(FWD)
REV.orients <- allOrients(REV)
FWD.orients
```

```{r}
# Pre-filter to remove Ns
fnFs.filtN <- file.path(path, "filtN", basename(fnFs))
fnRs.filtN <- file.path(path, "filtN", basename(fnRs))
filterAndTrim(fnFs, fnFs.filtN, fnRs, fnRs.filtN, maxN = 0, multithread = TRUE)
```

```{r}
# Primer checking function
primerHits <- function(primer, fn) {
    nhits <- vcountPattern(primer, sread(readFastq(fn)), fixed = FALSE)
    return(sum(nhits > 0))
}
```

```{r}
# Check primer orientations
rbind(
    FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.filtN[[1]]),
    FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs.filtN[[1]]),
    REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs.filtN[[1]]),
    REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.filtN[[1]])
)
```

```{r}
# set up cutadapt
cutadapt <- "C:/Python313/Scripts/cutadapt.exe" # path to cutadapt
system2(cutadapt,args = "--version")
```

```{r}
path.cut <- file.path(path, "cutadapt")
if(!dir.exists(path.cut)) dir.create(path.cut)
fnFs.cut <- file.path(path.cut, basename(fnFs))
fnRs.cut <- file.path(path.cut, basename(fnRs))

FWD.RC <- dada2:::rc(FWD)
REV.RC <- dada2:::rc(REV)
# Trim FWD and the reverse-complement of REV off of R1 (forward reads)
R1.flags <- paste("-g", FWD, "-a", REV.RC, "-e 0.2") 
# Trim REV and the reverse-complement of FWD off of R2 (reverse reads)
R2.flags <- paste("-G", REV, "-A", FWD.RC, "-e 0.2") 
# Run Cutadapt
for(i in seq_along(fnFs)) {
  system2(cutadapt, args = c(R1.flags, R2.flags, "-n", 2, # -n 2 required to remove FWD and REV from reads
                             "-o", fnFs.cut[i], "-p", fnRs.cut[i], # output files
                             fnFs.filtN[i], fnRs.filtN[i])) # input files
}
```

```{r}
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.cut[[1]]), FWD.ReverseReads = sapply(FWD.orients,
    primerHits, fn = fnRs.cut[[1]]), REV.ForwardReads = sapply(REV.orients, primerHits,
    fn = fnFs.cut[[1]]), REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.cut[[1]]))
```
## Only few reads remaining I will just leave it be
```{r}
cutFs <- sort(list.files(path.cut, pattern = "_1.fastq", full.names = TRUE))
cutRs <- sort(list.files(path.cut, pattern = "_2.fastq", full.names = TRUE))
```

```{r}
# Extract sample names, assuming filenames have format:
get.sample.name <- function(fname) strsplit(basename(fname), "_")[[1]][1]
sample.names <- unname(sapply(cutFs, get.sample.name))
head(sample.names)
```

```{r}
plotQualityProfile(cutFs[1:2])
```

```{r}
plotQualityProfile(cutRs[1:2])
```

```{r}
filtFs <- file.path(path.cut, "filtered", basename(cutFs))
filtRs <- file.path(path.cut, "filtered", basename(cutRs))
```

```{r}
# Function to count lines in fastq file and divide by 4 (since each read has 4 lines)
count_fastq_reads <- function(file) {
    return(length(readLines(file)) / 4)
}

# Get counts
forward_counts <- numeric(length(cutFs))
reverse_counts <- numeric(length(cutRs))

# Count each file
for(i in seq_along(cutFs)) {
    forward_counts[i] <- count_fastq_reads(cutFs[i])
    reverse_counts[i] <- count_fastq_reads(cutRs[i])
    cat("File", i, basename(cutFs[i]), ":", 
        forward_counts[i], "forward reads,",
        reverse_counts[i], "reverse reads\n")
}

# Find mismatches
mismatches <- which(forward_counts != reverse_counts)
if(length(mismatches) > 0) {
    cat("\nMismatched files:\n")
    for(i in mismatches) {
        cat(basename(cutFs[i]), ":", 
            forward_counts[i], "forward reads,",
            reverse_counts[i], "reverse reads\n")
    }
}
```

### There was a mismatched file: Mismatched files:
ERR3182449_1.fastq : 565 forward reads, 569 reverse reads
### Will just take it out

```{r}
# Get the file paths
cutFs <- sort(list.files("3-fastq/cutadapt", pattern="_1.fastq", full.names = TRUE))
cutRs <- sort(list.files("3-fastq/cutadapt", pattern="_2.fastq", full.names = TRUE))

# Remove the problematic sample
bad_sample <- which(basename(cutFs) == "ERR3182449_1.fastq")
cutFs <- cutFs[-bad_sample]
cutRs <- cutRs[-bad_sample]

# Create filtered directories and filenames 
if(!dir.exists("3-fastq/filtered")) dir.create("3-fastq/filtered")
filtFs <- file.path("3-fastq/filtered", basename(cutFs))
filtRs <- file.path("3-fastq/filtered", basename(cutRs))

# Now run filterAndTrim
out <- filterAndTrim(cutFs, filtFs,
                    cutRs, filtRs,
                    truncLen=c(200,160),
                    maxN=0, maxEE=c(2,2),
                    truncQ=2, rm.phix=TRUE,
                    compress=TRUE, multithread=TRUE)
```

### looking at the quality trimming at 200 and 160, V4 region so enough overlap

```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
```

```{r}
errR <- learnErrors(filtRs, multithread = TRUE)
```

```{r}
plotErrors(errF, nominalQ = TRUE)
```

```{r}
dadaFs <- dada(filtFs, err = errF, multithread = TRUE)
dadaRs <- dada(filtRs, err = errR, multithread = TRUE)
```

```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
```
## Construct Sequence Table
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```
## Remove chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
```
### Inspect distribution of sequence lengths
```{r}
table(nchar(getSequences(seqtab.nochim)))
```
## Track Reads through the pipeline
```{r}
# Get sample names from the filtered files
sample.names <- sapply(strsplit(basename(filtFs), "_"), `[`, 1)

# Track reads through the pipeline
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN),
               rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```
## Taxonomy Assignment
```{r}
taxa <- assignTaxonomy(seqtab.nochim, "../silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
```

```{r}
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```

## Species Level Assignment
```{r}
set.seed(123)
taxa.species <- addSpecies(taxa, "../silva_species_assignment_v138.1.fa.gz")
```

```{r}
taxa.print <- taxa.species # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```

```{r}
table(taxa.print[,1]) # Show the different kingdoms (should be only bacteria)
table(taxa.print[,2]) # Show the different phyla
table(is.na(taxa.print[,2])) # is there any NA phyla?
```

```{r}
## saving the seqtab.nochim and taxa as rds
saveRDS(seqtab.nochim, file.path(path, "seqtab.nochim_3.rds"))
saveRDS(taxa, file.path(path, "taxa_3.rds"))
saveRDS(taxa.species, file.path(path, "taxa.species_3.rds"))
```

