---
title: "DADA Analysis Study 9"
author: "Anushka KC"
date: "2024-10-27"
output: html_document
---

```{r}
library(dada2); packageVersion("dada2")
```

```{r}
path <- "fastq"
list.files(path)
```

```{r}
fnFs <- sort(list.files(path, pattern="_1.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_2.fastq", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```


```{r}
plotQualityProfile(fnFs[1:2])
```

```{r}
plotQualityProfile(fnRs[1:2])
```

```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```

```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(150, 150),
              maxN=0, maxEE=c(5,5), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=FALSE) # On Windows set multithread=FALSE
```

```{r}
head(out)
```
```{r}
filtered_samples <- rownames(out)[out[, "reads.out"] == 0]
num_filtered_samples <- length(filtered_samples)
cat("Number of samples filtered out:", num_filtered_samples, "\n")
```

### Filtering out the samples that have zero reads and not including them in the analysis below
```{r}
pass_filter <- out[, 2] > 0
filtF_pass <- filtFs[pass_filter]
filtR_pass <- filtRs[pass_filter]
```

```{r}
errF <- learnErrors(filtF_pass, multithread=TRUE)
```

```{r}
errR <- learnErrors(filtR_pass, multithread=TRUE)
```

```{r}
plotErrors(errF, nominalQ=TRUE)
```

```{r}
dadaFs <- dada(filtF_pass, err=errF, multithread=TRUE)
```

```{r}
dadaRs <- dada(filtR_pass, err=errR, multithread=TRUE)
```

```{r}
dadaFs[[1]]
```

```{r}
mergers <- mergePairs(dadaFs, filtF_pass, dadaRs, filtR_pass, verbose=TRUE)
```

```{r}
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```

```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```

```{r}
# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```

```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
```

```{r}
dim(seqtab.nochim)
```

```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```

```{r}
taxa <- assignTaxonomy(seqtab.nochim, "../silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
```

```{r}
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```

```{r}
library(DECIPHER); packageVersion("DECIPHER")
```

```{r}
library(phangorn); packageVersion("phangorn")
```

```{r}
taxa.species <- addSpecies(taxa, "../silva_species_assignment_v138.1.fa.gz")
```

```{r}
ASVs.nochim = DNAStringSet(colnames(seqtab.nochim))
names(ASVs.nochim) = paste0("ASV", 1:ncol(seqtab.nochim))
```

```{r}
alignment = AlignSeqs(ASVs.nochim, anchor=NA, processors=30)
```

```{r}
phang.align <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phang.align)
treeNJ <- NJ(dm)

fit = pml(treeNJ, data=phang.align)
fitGTR <- update(fit, k=4, inv=0.2)
#fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE, rearrangement = "stochastic", control = pml.control(trace = 0))
save(fitGTR, file=file.path("fitGTR.RData"))
```

### Loading Metadata
```{r}
mdata <- read.csv("metadata.csv")
```

```{r}
mdata2 <- mdata[match(rownames(seqtab.nochim), mdata$Run), ]
rownames(mdata2) <- mdata2$Run

ASVs.nochim <- DNAStringSet(colnames(seqtab.nochim))
names(ASVs.nochim) <- paste0("ASV", 1:ncol(seqtab.nochim))

tmp.seqtab <- seqtab.nochim
colnames(tmp.seqtab) <- names(ASVs.nochim)
tmp.taxa <- taxa.species
rownames(tmp.taxa) <- names(ASVs.nochim)
```

### Creating Phyloseq Object
```{r}
library(phyloseq); packageVersion("phyloseq")
```

```{r}
ps <- phyloseq(
             otu_table(tmp.seqtab, taxa_are_rows=FALSE),
             sample_data(mdata2),
             tax_table(tmp.taxa),
             refseq(ASVs.nochim),
             phy_tree(fitGTR$tree))

ps
```

```{r}
save(ps, file=file.path("phyloseq_nochim_silva.RData"))
```

#### Saving ASV/OTU table
```{r}
OTU <- as(otu_table(ps), "matrix")
if(taxa_are_rows(ps)){OTU <- t(OTU)}
# Coerce to data.frame
OTUdf <- as.data.frame(OTU)
```

```{r}
write.table(OTUdf, "ASV_OTU_Table_Study9.tsv", row.names = TRUE)
```

#### Taxonomy Table
```{r}
taxonomy <- as(tax_table(ps), "matrix")
if(taxa_are_rows(ps)){taxonomy <- t(taxonomy)}
# Coerce to data.frame
taxonomydf <- as.data.frame(taxonomy)
```

```{r}
write.table(taxonomy, "Taxonomy_Study9.tsv", row.names = TRUE)
```

```{r}
write.csv(seqtab.nochim, "seqtab_nochim.csv", row.names = TRUE)
```

### Save SeqTab as RDS
```{r}
saveRDS(seqtab.nochim, "9_seqtab.nochim.rds")
```
